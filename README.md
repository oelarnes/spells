# ğŸª„ spells âœ¨

**spells** is a python package that tutors up customizable, optimized analysis of the public data sets provided by [17Lands](https://www.17lands.com/) and exiles the annoying, fiddly, and slow parts of your workflow. Spells exposes one first-class function, `summon`, which summons a Polars DataFrame to the battlefield.

```
$ spells add DSK
ğŸª„ spells âœ¨ [data home]=/Users/joel/.local/share/spells/

ğŸª„ add âœ¨ Downloading draft dataset from 17Lands.com
100% [......................................................................] 250466473 / 250466473
ğŸª„ add âœ¨ File /Users/joel/.local/share/spells/external/DSK/DSK_PremierDraft_draft.csv written
ğŸª„ clear-cache âœ¨ No local cache found for set DSK
ğŸª„ add âœ¨ Downloading game dataset from 17Lands.com
100% [........................................................................] 77145600 / 77145600
ğŸª„ add âœ¨ File /Users/joel/.local/share/spells/external/DSK/DSK_PremierDraft_game.csv written
ğŸª„ clear-cache âœ¨ No local cache found for set DSK
ğŸª„ add âœ¨ Fetching card data from mtgjson.com and writing card csv file
ğŸª„ add âœ¨ Wrote 287 lines to file /Users/joel/.local/share/spells/external/DSK/DSK_card.csv
$ ipython
```

```python
In [1]: import spells
In [2]: %time spells.summon('DSK')
CPU times: user 4min 23s, sys: 49.6 s, total: 5min 13s
Wall time: 2min 23s
Out [2]:
shape: (286, 14)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ name                       â”† color â”† rarity   â”† num_seen â”† â€¦ â”† num_oh â”† oh_wr    â”† num_gih â”† gih_wr   â”‚
â”‚ ---                        â”† ---   â”† ---      â”† ---      â”†   â”† ---    â”† ---      â”† ---     â”† ---      â”‚
â”‚ str                        â”† str   â”† str      â”† i64      â”†   â”† i64    â”† f64      â”† i64     â”† f64      â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡
â”‚ Abandoned Campground       â”† null  â”† common   â”† 178750   â”† â€¦ â”† 21350  â”† 0.559672 â”† 49376   â”† 0.547594 â”‚
â”‚ Abhorrent Oculus           â”† U     â”† mythic   â”† 6676     â”† â€¦ â”† 4255   â”† 0.564042 â”† 11287   â”† 0.593337 â”‚
â”‚ Acrobatic Cheerleader      â”† W     â”† common   â”† 308475   â”† â€¦ â”† 34177  â”† 0.541709 â”† 74443   â”† 0.532152 â”‚
â”‚ Altanak, the Thrice-Called â”† G     â”† uncommon â”† 76981    â”† â€¦ â”† 13393  â”† 0.513925 â”† 34525   â”† 0.539175 â”‚
â”‚ Anthropede                 â”† G     â”† common   â”† 365380   â”† â€¦ â”† 8075   â”† 0.479876 â”† 20189   â”† 0.502353 â”‚
â”‚ â€¦                          â”† â€¦     â”† â€¦        â”† â€¦        â”† â€¦ â”† â€¦      â”† â€¦        â”† â€¦       â”† â€¦        â”‚
â”‚ Wildfire Wickerfolk        â”† GR    â”† uncommon â”† 98040    â”† â€¦ â”† 18654  â”† 0.592366 â”† 42251   â”† 0.588696 â”‚
â”‚ Winter's Intervention      â”† B     â”† common   â”† 318565   â”† â€¦ â”† 27552  â”† 0.537638 â”† 66921   â”† 0.548453 â”‚
â”‚ Winter, Misanthropic Guide â”† BGR   â”† rare     â”† 52091    â”† â€¦ â”† 1261   â”† 0.462331 â”† 3183    â”† 0.479422 â”‚
â”‚ Withering Torment          â”† B     â”† uncommon â”† 76237    â”† â€¦ â”† 15901  â”† 0.511729 â”† 39323   â”† 0.542024 â”‚
â”‚ Zimone, All-Questioning    â”† GU    â”† rare     â”† 20450    â”† â€¦ â”† 9510   â”† 0.654574 â”† 23576   â”† 0.616686 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

In [3]: %time spells.summon('DSK')
CPU times: user 16.3 ms, sys: 66.2 ms, total: 82.5 ms
Wall time: 80.8 ms
```

Coverting to pandas DataFrame is as simple as invoking the chained call `summon(...).to_pandas()`.

Spells is not affiliated with 17Lands. Please review the Usage Guidelines for 17lands data before using Spells, and consider supporting their patreon. Spells is free and open-source; please consider contributing and feel free to make use of the source code under the terms of the MIT license.

## spells

- Uses [Polars](https://docs.pola.rs/) for high-performance, multi-threaded, chunked aggregations of large datasets
- Uses Polars to power an expressive query language for specifying custom extensions and optimizing complex queries
- Supports calculating the standard aggregations and measures out of the box with no arguments (ALSA, GIH WR, etc)
- Caches aggregate DataFrames in the local file system automatically for instantaneous reproduction of previous analysis
- Manages grouping and filtering by built-in and custom columns at the row level
- Provides over 50 explicitly specified, enumerated, documented custom column definitions
- Supports "Deck Color Data" aggregations out of the box.
- Provides a CLI tool `spells [add|refresh|clear_local|remove|info] [SET]` to download and manage external files
- Downloads and manages public datasets from 17Lands
- Downloads and models booster configuration and card data from [MTGJSON](https://mtgjson.com/)
- Is fully typed, linted, and statically analyzed for support of advanced IDE features
- Provides optional enums for all base columns and built-in extensions, as well as for custom extension parameters
- Uses Polars expressions to support second-stage aggregations like z-scores out of the box with one call to summon

## summon

`summon` takes four optional arguments, allowing a fully declarative specification of your desired analysis. Basic functionality not provided by this api can often be managed by simple chained calls using the polars API, e.g. sorting and post-agg filtering.
  - `columns` specifies the desired output columns
    ```python
    >>> spells.summon('BLB', columns=["gp_wr", "ata"])
    shape: (276, 3)
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ name                    â”† gp_wr    â”† ata      â”‚
    â”‚ ---                     â”† ---      â”† ---      â”‚
    â”‚ str                     â”† f64      â”† f64      â”‚
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡
    â”‚ Agate Assault           â”† 0.538239 â”† 6.162573 â”‚
    â”‚ Agate-Blade Assassin    â”† 0.546623 â”† 7.904145 â”‚
    â”‚ Alania's Pathmaker      â”† 0.538747 â”† 8.886676 â”‚
    â”‚ Alania, Divergent Storm â”† 0.489466 â”† 5.601287 â”‚
    â”‚ Artist's Talent         â”† 0.466227 â”† 7.515328 â”‚
    â”‚ â€¦                       â”† â€¦        â”† â€¦        â”‚
    â”‚ Wick, the Whorled Mind  â”† 0.525859 â”† 3.618172 â”‚
    â”‚ Wildfire Howl           â”† 0.513218 â”† 8.632178 â”‚
    â”‚ Wishing Well            â”† 0.533792 â”† 8.56727  â”‚
    â”‚ Ygra, Eater of All      â”† 0.570971 â”† 1.559604 â”‚
    â”‚ Zoraline, Cosmos Caller â”† 0.570701 â”† 2.182625 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    ```
  - `group_by` specifies the grouping by one or more columns. By default, group by card names, but optionally group by any of a large set of fundamental and derived columns, including card attributes and your own custom extension.
    ```python
    >>> spells.summon('BLB', columns=["num_won", "num_games", "game_wr"], group_by=["main_colors"], filter_spec={"num_colors": 2})
    shape: (10, 4)
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ main_colors â”† num_won â”† num_games â”† game_wr  â”‚
    â”‚ ---         â”† ---     â”† ---       â”† ---      â”‚
    â”‚ str         â”† u32     â”† u32       â”† f64      â”‚
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡
    â”‚ BG          â”† 85022   â”† 152863    â”† 0.556197 â”‚
    â”‚ BR          â”† 45900   â”† 81966     â”† 0.559988 â”‚
    â”‚ RG          â”† 34641   â”† 64428     â”† 0.53767  â”‚
    â”‚ UB          â”† 30922   â”† 57698     â”† 0.535928 â”‚
    â”‚ UG          â”† 59879   â”† 109145    â”† 0.548619 â”‚
    â”‚ UR          â”† 19638   â”† 38679     â”† 0.507717 â”‚
    â”‚ WB          â”† 59480   â”† 107443    â”† 0.553596 â”‚
    â”‚ WG          â”† 76134   â”† 136832    â”† 0.556405 â”‚
    â”‚ WR          â”† 49712   â”† 91224     â”† 0.544944 â”‚
    â”‚ WU          â”† 16483   â”† 31450     â”† 0.524102 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    ```
  - `filter_spec` specifies a row-level filter for the dataset, using an intuitive custom query formulation
    ```python
    >>> from spells.enums import ColName
    >>> spells.summon('BLB', columns=["game_wr"], group_by=["player_cohort"], filter_spec={'lhs': 'num_mulligans', 'op': '>', 'rhs': 0})
    shape: (4, 2)
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ player_cohort â”† game_wr  â”‚
    â”‚ ---           â”† ---      â”‚
    â”‚ str           â”† f64      â”‚
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡
    â”‚ Bottom        â”† 0.33233  â”‚
    â”‚ Middle        â”† 0.405346 â”‚
    â”‚ Other         â”† 0.406151 â”‚
    â”‚ Top           â”† 0.475763 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    ```
  - `extensions` allows for the specification of arbitrarily complex derived columns and aggregations, including custom columns built on top of custom columns.
    ```python
    >>> import polars as pl
    >>> from spells.columns import ColumnDefinition
    >>> from spells.enums import ColType, View, ColName
    >>> ext = ColumnDefinition(
    ...     name='deq_base',
    ...     col_type=ColType.AGG,
    ...     expr=(pl.col('gp_wr') - pl.col('gp_wr_mean') + (14 - pl.col('ata')).pow(2) * 0.03 / (14 ** 2)) * pl.col('pct_gp'),
    ...     dependencies=['gp_wr', 'gp_wr_mean', 'ata', 'pct_gp']
    ...)
    >>> spells.summon('DSK', columns=['deq_base', 'color', 'rarity'], filter_spec={'player_cohort': 'Top'}, extensions=[ext])
    ...     .filter(pl.col('deq_base').is_finite())
    ...     .filter(pl.col('rarity').is_in(['common', 'uncommon'])
    ...     .sort('deq_base', descending=True)
    ...     .head(10)
    shape: (10, 4)
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ name                     â”† deq_base â”† rarity   â”† color â”‚
    â”‚ ---                      â”† ---      â”† ---      â”† ---   â”‚
    â”‚ str                      â”† f64      â”† str      â”† str   â”‚
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
    â”‚ Sheltered by Ghosts      â”† 0.03945  â”† uncommon â”† W     â”‚
    â”‚ Optimistic Scavenger     â”† 0.036131 â”† uncommon â”† W     â”‚
    â”‚ Midnight Mayhem          â”† 0.034278 â”† uncommon â”† RW    â”‚
    â”‚ Splitskin Doll           â”† 0.03423  â”† uncommon â”† W     â”‚
    â”‚ Fear of Isolation        â”† 0.033901 â”† uncommon â”† U     â”‚
    â”‚ Floodpits Drowner        â”† 0.033198 â”† uncommon â”† U     â”‚
    â”‚ Gremlin Tamer            â”† 0.032048 â”† uncommon â”† UW    â”‚
    â”‚ Arabella, Abandoned Doll â”† 0.032008 â”† uncommon â”† RW    â”‚
    â”‚ Unnerving Grasp          â”† 0.030278 â”† uncommon â”† U     â”‚
    â”‚ Oblivious Bookworm       â”† 0.028605 â”† uncommon â”† GU    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
    ```
    
    Note the use of chained calls to the Polars DataFrame api to perform manipulations on the result of `summon`.
    
## Installation

Spells is available on PyPI as *spells-mtg*, and can be installed using pip or any package manager:

`pip install spells-mtg`

Spells is still in development and could benefit from many new features and improvements. As such, you might rather clone this repository and install locally. It is set up to use pdm, but it's just a regular old python package and you can install with your normal workflow.

If you are new to Python, I recommend using a package manager like poetry, pdm or uv to create a virtual environment and manage your project.

## Performance

Spells provides several features out of the box to optimize performance to the degree possible given its generality.

### Query Optimization

Firstly, it is built on top of Polars, a modern, well-supported DataFrame engine that enables declarative query plans and lazy evaluation, allowing for automatic performance optimization in the execution of the query plan. Spells selects only the necessary columns for your analysis, at the lowest depth possible per column, and uses "concat" rather than "with" throughout to ensure the best performance and flexibility for optimization. 

By default, Polars loads the entire selection into memory before aggregation for optimal time performance. For query plans that are too memory-intensive, Spells exposes the Polars parameter `streaming`, which performs aggregations in chunks based on available system resources. `polars.Config` exposes settings for further tweaking your execution plan. Spells and Polars do not support distributed computation.

### Local Caching

Additionally, by default, Spells caches the results of expensive aggregations in the local file system as parquet files, which by default are found under the `data/local` path from the execution directory, which can be configured using the environment variable `SPELLS_PROJECT_DIR`. Query plans which request the same set of first-stage aggregations (sums over base rows) will attempt to locate the aggregate data in the cache before calculating. This guarantees that a repeated call to `summon` returns instantaneously.

When refreshing a given set's data files from 17Lands using the provided cli, the cache for that set is automatically cleared. Additionally `summon` has named arguments `read_cache` and `write_cache`, and the project exposes `spells.cache.clear(set_code: str)` for further control.

# Documentation
In order to give a valid specification for more complex queries, it's important to understand a bit about what Spells is doing under the hood.

## Basic Concepts
Let's briefly review the structure of the underlying data. Spells supports aggregations on two of the three large data sets provided by 17Lands, which
are identified as "views" within Spells. First there is *draft*, which is the source for information about draft picks. The row model is single draft picks with pack and pool context. Unlike *game*, there are two different paradigms for aggregating over card names. 

First, one can group by the value of the "pick" column and sum numerical column values. This is how ATA is calculated. In Spells, we tag columns to be summed in this way as *pick_sum* columns. For example, "taken_at" is equivalent to "pick_number", but whereas the latter is available for grouping, "taken_at" is summed over groups. 

Second, certain columns are pivoted horizontally within the raw data and suffixed with card names, for example "pack_card_Savor". In Spells we tag such columns as *name_sum*, and group by non-name columns and sum before unpivoting. The columns are identified by their prefix only and Spells handles the mapping. 

A standard way to aggregate information in non-*name_sum* columns over names is to multiply that column over the pivoted column. For example, to calculate the *name_sum* column "last_seen", used in ALSA, we multiply "pack_card" by a modified version of "pick_number".

In the *game* file, the row model represents games, and primarily uses *name_sum* aggregations for the familiar columns, such as "num_gih", from which win rates are derived. For groupings that do not use card names or card attributes (to recreate the "deck color data" page, for example), one can also specify *game_sum* columns which aggregate simply over rows.

### Aggregate View

Once aggregation columns, filters and groupings are determined at the row level for each of the required base views, Spells asks Polars to sum over groups and unpivot as needed to produce the "base aggregate view", which fixes the row model (pre-card attributes) to the provided base groupings. This base aggregate view is cached by default to the local file system, keyed by the *manifest*, which is a function of the specification provided by the user.

Next, card attributes are calculated and joined to the base aggregate view by name, and an additional grouping is performed if requested by the user to produce the *aggregate view*.

A final extension and selection stage is applied to the aggregate view, which is where weighted averages like GIH WR are calculated. Polars expression language enables aggregations to be represented as expressions and broadcast back to the row level, enabling Spells to support arbitrary chains of aggregation and extension at the aggregate view level. For example, one could calculate the mean of a metric over groups by archetype, regress a metric by a function of that mean, then calculate the mean of that regressed metric, all expressed declaratively as column expressions and simply specified by name in the `summon` api call.

So that's it, that's what Spells does from a high level. `summon` will hand off a Polars DataFrame which can be cast to pandas, sorted, filtered, used to be generate plots or whatever you like. If a task can be handled as easily via a chained call or outside library, it should stay that way, but if you have a request for features specific to the structure of limited data that could be handled in a general way, please reach out! In particular I am interested in scientific workflows like maximum likelihood estimation, but I haven't yet considered how to build it into Spells.

## CLI

Spells includes a command-line interface `spells` to manage your external data files and local cache. Spells will download files to an appropriate file location on your system, 
typically `~/.local/share/spells` on Unix-like platforms and `C:\Users\{Username}\AppData\Local\Spells` on Windows. If you like, create an environment variable `SPELLS_DATA_HOME` 
in your shell profile or virtual environment to specify the target directory for your files. To use `spells`, make sure Spells in installed in your environment 
using pip or a package manager, and type `spells help` into your shell, or dive in with `spells add DSK` or your favorite set.

# Roadmap to 1.0

- [ ] Support Traditional and Premier datasets (currently only Premier is supported)
- [ ] Implement GNS and name-mapped column exprs
- [ ] Enable configuration using $XDG_CONFIG_HOME/cfg.toml
- [ ] Support min and max aggregations over base views
- [ ] Enhanced profiling
- [ ] Testing of streaming mode
- [ ] Optimized caching strategy
- [ ] Organize and analyze daily downloads from 17Lands (not a scraper!)
- [ ] Helper functions to generate second-order analysis by card name
- [ ] Helper functions for common plotting paradigms
- [ ] Example notebooks
- [ ] Scientific workflows: regression, MLE, etc


